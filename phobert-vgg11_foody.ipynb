{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, utils, models\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nfrom torch.autograd import Variable\nimport pandas as pd\nimport os\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\nimport pandas as pd\nimport torch\nimport numpy\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoModel, AutoTokenizer\nfrom sklearn.svm import SVC\nfrom joblib import dump\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data.dataloader import default_collate\nfrom transformers import XLMRobertaTokenizer, XLMRobertaXLModel\nfrom transformers import XLNetTokenizer, XLNetModel\nimport random\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision.ops.focal_loss as fl\nimport tensorflow_addons as tfa\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-15T10:47:38.549346Z","iopub.execute_input":"2022-12-15T10:47:38.550191Z","iopub.status.idle":"2022-12-15T10:47:50.575022Z","shell.execute_reply.started":"2022-12-15T10:47:38.550094Z","shell.execute_reply":"2022-12-15T10:47:50.573982Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n.datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"TRAIN1_DIR = '/kaggle/input/foody-data-after-pre/pre_train.csv'\nTRAIN2_DIR = '/kaggle/input/foody-data-after-pre/data2_processed.csv'\nIMAGE1_DIR = '/kaggle/input/foody-image/images/hihi{}_0__image.jpg'\nIMAGE2_DIR = '/kaggle/input/image-crawl/image2/hihi{}_0__image.jpg'\nIMAGE_TEST = '/kaggle/input/foody-image-test/image_for_test/hihi{}_0__image.jpg'\nTEST_DIR = '/kaggle/input/foody-data-after-pre/pre_test.csv'\nVAL_DIR = '/kaggle/input/foody-data-after-pre/val_labelled.csv'","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.577069Z","iopub.execute_input":"2022-12-15T10:47:50.577597Z","iopub.status.idle":"2022-12-15T10:47:50.591393Z","shell.execute_reply.started":"2022-12-15T10:47:50.577566Z","shell.execute_reply":"2022-12-15T10:47:50.590504Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(25)\nnp.random.seed(25)\nrandom.seed(25)\n\ncudnn.benchmark = True\ncudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.594761Z","iopub.execute_input":"2022-12-15T10:47:50.595029Z","iopub.status.idle":"2022-12-15T10:47:50.605915Z","shell.execute_reply.started":"2022-12-15T10:47:50.595004Z","shell.execute_reply":"2022-12-15T10:47:50.604997Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(TRAIN1_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.610364Z","iopub.execute_input":"2022-12-15T10:47:50.610624Z","iopub.status.idle":"2022-12-15T10:47:50.759309Z","shell.execute_reply.started":"2022-12-15T10:47:50.610585Z","shell.execute_reply":"2022-12-15T10:47:50.758279Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = df.drop(\"Unnamed: 0\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.760710Z","iopub.execute_input":"2022-12-15T10:47:50.761080Z","iopub.status.idle":"2022-12-15T10:47:50.776668Z","shell.execute_reply.started":"2022-12-15T10:47:50.761041Z","shell.execute_reply":"2022-12-15T10:47:50.775754Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df['Rating'] = df['Rating'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.779319Z","iopub.execute_input":"2022-12-15T10:47:50.780116Z","iopub.status.idle":"2022-12-15T10:47:50.786865Z","shell.execute_reply.started":"2022-12-15T10:47:50.780080Z","shell.execute_reply":"2022-12-15T10:47:50.785413Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.788563Z","iopub.execute_input":"2022-12-15T10:47:50.788955Z","iopub.status.idle":"2022-12-15T10:47:50.855308Z","shell.execute_reply.started":"2022-12-15T10:47:50.788897Z","shell.execute_reply":"2022-12-15T10:47:50.854165Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"list_image_paths = []\n\nfor i in range(df.shape[0]):\n    list_image_paths.append(IMAGE1_DIR.format(i))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.856779Z","iopub.execute_input":"2022-12-15T10:47:50.859227Z","iopub.status.idle":"2022-12-15T10:47:50.873342Z","shell.execute_reply.started":"2022-12-15T10:47:50.859139Z","shell.execute_reply":"2022-12-15T10:47:50.872263Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['image_paths'] = list_image_paths","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.874809Z","iopub.execute_input":"2022-12-15T10:47:50.875736Z","iopub.status.idle":"2022-12-15T10:47:50.885835Z","shell.execute_reply.started":"2022-12-15T10:47:50.875699Z","shell.execute_reply":"2022-12-15T10:47:50.884879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-15T10:47:50.890504Z","iopub.execute_input":"2022-12-15T10:47:50.891197Z","iopub.status.idle":"2022-12-15T10:47:50.910387Z","shell.execute_reply.started":"2022-12-15T10:47:50.891160Z","shell.execute_reply":"2022-12-15T10:47:50.909589Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      len                                            Comment  Rating  \\\n0      13  xôi dẻo đồ_ăn đậm vị hộp xôi được lót lá trông...       1   \n1      53  gọi ship 1 xuất cari gà bánh naan và 3 miếng g...       0   \n2      48  thời_tiết lạnh như này cả nhà rủ nhau đến lega...       1   \n3      57  em có đọc review thấy mng bảo trà sữa nướng đề...       0   \n4      92  đồ_ăn rất ngon nhà_hàng cũng rất đẹp tất_cả đề...       1   \n...   ...                                                ...     ...   \n9066   30  thực_sự mà nói thấy mọi người đánh_giá nhiều q...       1   \n9067  134  lẩu thái tômyum đc 19 lò_đúc hbt hn theo đánh_...       1   \n9068   45  ngay từ lúc đầu_tiên bước vào nhà_hàng đã được...       1   \n9069   17  đặt ăn thử mà thấy ngón cá emo rất mê sẽ còn ủ...       1   \n9070  125  nay xem bóng_đá vn lười nấu cơm nghe các bạn g...       1   \n\n                                            image_paths  \n0     /kaggle/input/foody-image/images/hihi0_0__imag...  \n1     /kaggle/input/foody-image/images/hihi1_0__imag...  \n2     /kaggle/input/foody-image/images/hihi2_0__imag...  \n3     /kaggle/input/foody-image/images/hihi3_0__imag...  \n4     /kaggle/input/foody-image/images/hihi4_0__imag...  \n...                                                 ...  \n9066  /kaggle/input/foody-image/images/hihi9066_0__i...  \n9067  /kaggle/input/foody-image/images/hihi9067_0__i...  \n9068  /kaggle/input/foody-image/images/hihi9068_0__i...  \n9069  /kaggle/input/foody-image/images/hihi9069_0__i...  \n9070  /kaggle/input/foody-image/images/hihi9070_0__i...  \n\n[9071 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>len</th>\n      <th>Comment</th>\n      <th>Rating</th>\n      <th>image_paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>xôi dẻo đồ_ăn đậm vị hộp xôi được lót lá trông...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi0_0__imag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53</td>\n      <td>gọi ship 1 xuất cari gà bánh naan và 3 miếng g...</td>\n      <td>0</td>\n      <td>/kaggle/input/foody-image/images/hihi1_0__imag...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>48</td>\n      <td>thời_tiết lạnh như này cả nhà rủ nhau đến lega...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi2_0__imag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57</td>\n      <td>em có đọc review thấy mng bảo trà sữa nướng đề...</td>\n      <td>0</td>\n      <td>/kaggle/input/foody-image/images/hihi3_0__imag...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92</td>\n      <td>đồ_ăn rất ngon nhà_hàng cũng rất đẹp tất_cả đề...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi4_0__imag...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9066</th>\n      <td>30</td>\n      <td>thực_sự mà nói thấy mọi người đánh_giá nhiều q...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi9066_0__i...</td>\n    </tr>\n    <tr>\n      <th>9067</th>\n      <td>134</td>\n      <td>lẩu thái tômyum đc 19 lò_đúc hbt hn theo đánh_...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi9067_0__i...</td>\n    </tr>\n    <tr>\n      <th>9068</th>\n      <td>45</td>\n      <td>ngay từ lúc đầu_tiên bước vào nhà_hàng đã được...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi9068_0__i...</td>\n    </tr>\n    <tr>\n      <th>9069</th>\n      <td>17</td>\n      <td>đặt ăn thử mà thấy ngón cá emo rất mê sẽ còn ủ...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi9069_0__i...</td>\n    </tr>\n    <tr>\n      <th>9070</th>\n      <td>125</td>\n      <td>nay xem bóng_đá vn lười nấu cơm nghe các bạn g...</td>\n      <td>1</td>\n      <td>/kaggle/input/foody-image/images/hihi9070_0__i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9071 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Comment'] = df['Comment'].str.strip()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.912153Z","iopub.execute_input":"2022-12-15T10:47:50.912769Z","iopub.status.idle":"2022-12-15T10:47:50.930393Z","shell.execute_reply.started":"2022-12-15T10:47:50.912733Z","shell.execute_reply":"2022-12-15T10:47:50.929542Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = df[df['Comment']  != 'None']","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.931840Z","iopub.execute_input":"2022-12-15T10:47:50.932182Z","iopub.status.idle":"2022-12-15T10:47:50.939512Z","shell.execute_reply.started":"2022-12-15T10:47:50.932147Z","shell.execute_reply":"2022-12-15T10:47:50.938463Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# df_train, df_test = train_test_split(df, test_size=0.15, random_state=42)\n\ndf_train = df\ndf_val = pd.read_csv(VAL_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:50.941310Z","iopub.execute_input":"2022-12-15T10:47:50.941966Z","iopub.status.idle":"2022-12-15T10:47:51.028538Z","shell.execute_reply.started":"2022-12-15T10:47:50.941930Z","shell.execute_reply":"2022-12-15T10:47:51.027598Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_val['Rating'] = df_val['Rating'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.030040Z","iopub.execute_input":"2022-12-15T10:47:51.030418Z","iopub.status.idle":"2022-12-15T10:47:51.037138Z","shell.execute_reply.started":"2022-12-15T10:47:51.030378Z","shell.execute_reply":"2022-12-15T10:47:51.036025Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"list_image_paths = []\n\nfor i in range(df_val.shape[0]):\n    list_image_paths.append(IMAGE_TEST.format(i))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.039173Z","iopub.execute_input":"2022-12-15T10:47:51.039570Z","iopub.status.idle":"2022-12-15T10:47:51.049808Z","shell.execute_reply.started":"2022-12-15T10:47:51.039517Z","shell.execute_reply":"2022-12-15T10:47:51.048840Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_val['image_paths'] = list_image_paths","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.051226Z","iopub.execute_input":"2022-12-15T10:47:51.051744Z","iopub.status.idle":"2022-12-15T10:47:51.060928Z","shell.execute_reply.started":"2022-12-15T10:47:51.051708Z","shell.execute_reply":"2022-12-15T10:47:51.059745Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_2 = pd.read_csv(TRAIN2_DIR)\ndf_2 = df_2.drop(\"Unnamed: 0\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.062317Z","iopub.execute_input":"2022-12-15T10:47:51.063178Z","iopub.status.idle":"2022-12-15T10:47:51.175742Z","shell.execute_reply.started":"2022-12-15T10:47:51.063142Z","shell.execute_reply":"2022-12-15T10:47:51.174790Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_2['Rating'] = df_2['Rating'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.177313Z","iopub.execute_input":"2022-12-15T10:47:51.177662Z","iopub.status.idle":"2022-12-15T10:47:51.184172Z","shell.execute_reply.started":"2022-12-15T10:47:51.177627Z","shell.execute_reply":"2022-12-15T10:47:51.183047Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"list_image_paths = []\n\nfor i in range(df_2.shape[0]):\n    list_image_paths.append(IMAGE2_DIR.format(i))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.185884Z","iopub.execute_input":"2022-12-15T10:47:51.186314Z","iopub.status.idle":"2022-12-15T10:47:51.196652Z","shell.execute_reply.started":"2022-12-15T10:47:51.186279Z","shell.execute_reply":"2022-12-15T10:47:51.195716Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df_2['image_paths'] = list_image_paths","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.198180Z","iopub.execute_input":"2022-12-15T10:47:51.198641Z","iopub.status.idle":"2022-12-15T10:47:51.207233Z","shell.execute_reply.started":"2022-12-15T10:47:51.198606Z","shell.execute_reply":"2022-12-15T10:47:51.206374Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df_0_2 = df_2[df_2['Rating'] == 0].sample(1450)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.208842Z","iopub.execute_input":"2022-12-15T10:47:51.209178Z","iopub.status.idle":"2022-12-15T10:47:51.217998Z","shell.execute_reply.started":"2022-12-15T10:47:51.209145Z","shell.execute_reply":"2022-12-15T10:47:51.217147Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_0_2['Rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.219688Z","iopub.execute_input":"2022-12-15T10:47:51.220070Z","iopub.status.idle":"2022-12-15T10:47:51.231428Z","shell.execute_reply.started":"2022-12-15T10:47:51.220037Z","shell.execute_reply":"2022-12-15T10:47:51.230192Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0    1450\nName: Rating, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_1_2 = df_2[df_2['Rating'] == 1].sample(1000)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.232860Z","iopub.execute_input":"2022-12-15T10:47:51.233665Z","iopub.status.idle":"2022-12-15T10:47:51.241527Z","shell.execute_reply.started":"2022-12-15T10:47:51.233587Z","shell.execute_reply":"2022-12-15T10:47:51.240657Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_train = pd.concat([df_train[['Comment','image_paths','Rating']],\n                df_0_2[['Comment','image_paths','Rating']],\n                df_1_2[['Comment','image_paths','Rating']]\n               ])","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.242909Z","iopub.execute_input":"2022-12-15T10:47:51.243362Z","iopub.status.idle":"2022-12-15T10:47:51.253931Z","shell.execute_reply.started":"2022-12-15T10:47:51.243328Z","shell.execute_reply":"2022-12-15T10:47:51.253058Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.255300Z","iopub.execute_input":"2022-12-15T10:47:51.255883Z","iopub.status.idle":"2022-12-15T10:47:51.264023Z","shell.execute_reply.started":"2022-12-15T10:47:51.255845Z","shell.execute_reply":"2022-12-15T10:47:51.263037Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(11519, 3)"},"metadata":{}}]},{"cell_type":"code","source":"df_val['Rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.265559Z","iopub.execute_input":"2022-12-15T10:47:51.265921Z","iopub.status.idle":"2022-12-15T10:47:51.274752Z","shell.execute_reply.started":"2022-12-15T10:47:51.265887Z","shell.execute_reply":"2022-12-15T10:47:51.273613Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"1    4003\n0    1100\nName: Rating, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_val['Rating'] = df_val['Rating'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.276443Z","iopub.execute_input":"2022-12-15T10:47:51.276874Z","iopub.status.idle":"2022-12-15T10:47:51.282205Z","shell.execute_reply.started":"2022-12-15T10:47:51.276838Z","shell.execute_reply":"2022-12-15T10:47:51.281327Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.288400Z","iopub.execute_input":"2022-12-15T10:47:51.289116Z","iopub.status.idle":"2022-12-15T10:47:51.293519Z","shell.execute_reply.started":"2022-12-15T10:47:51.289082Z","shell.execute_reply":"2022-12-15T10:47:51.292448Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop_duplicates(['Comment'])","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.294709Z","iopub.execute_input":"2022-12-15T10:47:51.295665Z","iopub.status.idle":"2022-12-15T10:47:51.340379Z","shell.execute_reply.started":"2022-12-15T10:47:51.295630Z","shell.execute_reply":"2022-12-15T10:47:51.339385Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_train['Rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.341740Z","iopub.execute_input":"2022-12-15T10:47:51.342196Z","iopub.status.idle":"2022-12-15T10:47:51.350522Z","shell.execute_reply.started":"2022-12-15T10:47:51.342158Z","shell.execute_reply":"2022-12-15T10:47:51.349587Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1    8122\n0    3348\nName: Rating, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"### model","metadata":{}},{"cell_type":"code","source":"data_transform_train = transforms.Compose([\n        transforms.Resize((64,64)),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\ndata_transform_test = transforms.Compose([\n        transforms.Resize((64,64)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.351963Z","iopub.execute_input":"2022-12-15T10:47:51.353022Z","iopub.status.idle":"2022-12-15T10:47:51.361965Z","shell.execute_reply.started":"2022-12-15T10:47:51.352987Z","shell.execute_reply":"2022-12-15T10:47:51.361060Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class MultimodalDataset(Dataset):\n\n    def __init__(self, img_dir, labels, text, transform=None):\n        self.labels= labels\n        self.img_dir = img_dir\n        self.transform = transform\n        self.text = text\n\n    def __len__(self):\n        return len(self.img_dir)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.img_dir[idx]).convert('RGB')\n        label = self.labels[idx]\n        text = self.text[idx]\n\n        if self.transform:\n            image = self.transform(image)\n        \n\n        return [text, image, label]","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.363544Z","iopub.execute_input":"2022-12-15T10:47:51.363990Z","iopub.status.idle":"2022-12-15T10:47:51.374417Z","shell.execute_reply.started":"2022-12-15T10:47:51.363954Z","shell.execute_reply":"2022-12-15T10:47:51.373333Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nclass Multimodal_Bert_Vgg(nn.Module):\n    def __init__(self):\n        super(Multimodal_Bert_Vgg, self).__init__()\n        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)\n        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n        self.vgg = models.vgg11(pretrained=True).to(device)\n        self.vgg.classifier[6] = nn.Linear(4096, 256).to(device)\n\n        self.linear2 = nn.Linear(768,256).to(device)\n        \n        self.classifier = nn.Sequential(\n          nn.Dropout(0.2),\n          nn.Linear(in_features = 512, out_features = 256, bias=True).to(device),\n          nn.Dropout(0.1),\n          nn.Linear(in_features = 256, out_features = 2, bias=True).to(device)  \n        )\n        \n        self.criterior = nn.CrossEntropyLoss().to(device)\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        param_optimizer = list(self.bert.named_parameters())\n        self.optimizer =optim.AdamW(\n            [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n            {'params': self.classifier.parameters(), 'lr': 8e-5},\n            {'params': self.vgg.parameters(), 'lr': 2e-5},\n            {'params': self.linear2.parameters(), 'lr': 8e-5},\n            ],\n            lr = 2e-5\n        )\n\n    def tokenize(self,v_text, images, label, phase = 'train'):\n        v_tokenized = []\n        max_len = 256\n        for i_text in v_text:\n            i_text = standardize_data(i_text)\n            i_text = self.choose_sub_text(i_text)\n            line = self.tokenizer.encode(i_text, max_length = max_len)\n            v_tokenized.append(line)\n\n        padded = numpy.array([i + [1] * (max_len - len(i)) for i in v_tokenized])\n        attention_mask = numpy.where(padded == 1, 0, 1)\n        padded = torch.tensor(padded).to(torch.long)\n        attention_mask = torch.tensor(attention_mask)\n        \n        target = torch.tensor(label) \n        print(target)\n        if phase == 'train':\n            data_tensor = MultimodalDataset(img_dir = images, \n                        labels = label, \n                        text = padded, \n                        transform = data_transform_train)\n        else:\n            data_tensor = MultimodalDataset(img_dir = images, \n                        labels = label, \n                        text = padded, \n                        transform = data_transform_test)\n            \n        train_loader = DataLoader(dataset = data_tensor, batch_size = 32)\n        attention_mask = DataLoader(attention_mask, batch_size = 32)\n        \n        return train_loader, attention_mask\n    \n    def choose_sub_text(self, text):\n        tmp = len(text.split())\n        if tmp > 256:\n            words = text.split()\n            text = ' '.join(words[0:210]) + ' ' + ' '.join(words[-46:])\n            \n        return text\n    \n    def forward(self, input_ids, images, attention_mask):\n        _, output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n             return_dict=False\n        )\n        output = self.linear2(output)\n        output2 = self.vgg(images)\n        output = torch.cat((output, output2), 1)\n        output = self.classifier(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.375991Z","iopub.execute_input":"2022-12-15T10:47:51.376710Z","iopub.status.idle":"2022-12-15T10:47:51.396388Z","shell.execute_reply.started":"2022-12-15T10:47:51.376675Z","shell.execute_reply":"2022-12-15T10:47:51.395457Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def standardize_data(row):\n    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n        .replace(\";\", \" \").replace(\"“\", \" \") \\\n        .replace(\":\", \" \").replace(\"”\", \" \") \\\n        .replace('\"', \" \").replace(\"'\", \" \") \\\n        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n        .replace(\"-\", \" \").replace(\"?\", \" \") \\\n        .replace(\"  \",\" \").replace(\"  \",\" \") \\\n        .replace(')','').replace('(','') \\\n        .replace(\"—\",' ').replace(\"\\n\",' '). replace(\"\\t\",' ') \\\n        .replace('   ', ' ').replace('  ', ' ')\n            \n    return row","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.397591Z","iopub.execute_input":"2022-12-15T10:47:51.397850Z","iopub.status.idle":"2022-12-15T10:47:51.408229Z","shell.execute_reply.started":"2022-12-15T10:47:51.397826Z","shell.execute_reply":"2022-12-15T10:47:51.407196Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def train_model(bert, save_path, df_train, df_test, num_epochs=1, type_model = 'bert', check_fold = 1):\n        text_train = df_train['Comment'].to_list()\n        image_paths_train = df_train['image_paths'].to_list()\n        label_train = df_train['Rating'].to_list()\n        text_test = df_test['Comment'].to_list()\n        image_paths_test = df_test['image_paths'].to_list()\n        label_test = df_test['Rating'].to_list()\n        Data_train, attention_train = bert.tokenize(text_train, image_paths_train, label_train, 'train')\n        Data_test, attention_test = bert.tokenize(text_test, image_paths_test, label_test, 'test')\n        \n        dataloader_dict = {\n            'train' : Data_train,\n            'test' : Data_test\n        }\n        \n        check = 0\n        \n        \n        for epoch in range(num_epochs + 1):\n            if epoch == 0:\n                print()\n                continue\n            print(\"Epoch {}/{} \".format(epoch, num_epochs))\n\n            for phase in ['train', 'test']:\n                if phase == 'train':\n                    bert.train()\n                    attention = attention_train\n                else:\n                    bert.eval()\n                    attention = attention_test\n\n                epoch_loss = 0.0\n                epoch_corrects = 0\n\n                for (inputs, images, labels), i_attention in tqdm(zip(dataloader_dict[phase], attention), position=0, leave=True):\n                    inputs = inputs.to(device)\n                    images = images.to(device)\n                    labels = labels.to(device)\n                    i_attention = i_attention.to(device)\n\n                    bert.optimizer.zero_grad()\n\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = bert(inputs,images, i_attention)\n\n                        loss = bert.criterior(outputs, labels)\n\n                        _, preds = torch.max(outputs, 1)\n\n                        if phase == 'train':\n                            loss.backward()\n                            bert.optimizer.step()\n                            \n                            \n\n                        epoch_loss += loss.item() * inputs.size(0)\n                        epoch_corrects += torch.sum(preds == labels.data)\n                        del outputs\n                        torch.cuda.empty_cache()\n\n                epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n                epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n                \n                print(\"{} Loss: {:.4f}  Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n                \n                if check < epoch_acc and phase == 'test':\n                    check = epoch_acc\n                    torch.save(bert.state_dict(), \"./full_{}_model_fold{}.pth\".format(type_model, check_fold))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.409724Z","iopub.execute_input":"2022-12-15T10:47:51.410362Z","iopub.status.idle":"2022-12-15T10:47:51.425030Z","shell.execute_reply.started":"2022-12-15T10:47:51.410329Z","shell.execute_reply":"2022-12-15T10:47:51.424035Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### train","metadata":{}},{"cell_type":"code","source":"df_train = shuffle(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:47:51.426776Z","iopub.execute_input":"2022-12-15T10:47:51.427140Z","iopub.status.idle":"2022-12-15T10:47:51.438880Z","shell.execute_reply.started":"2022-12-15T10:47:51.427105Z","shell.execute_reply":"2022-12-15T10:47:51.438268Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"mb = Multimodal_Bert_Vgg()\ntrain_model(mb, './', df_train, df_val, num_epochs = 4, type_model = 'multimodal')\n# train_model(model,\"./\", df_train, df_test, num_epochs=epoch,type_model =type_model,check_fold = check_fold)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-15T10:47:51.440300Z","iopub.execute_input":"2022-12-15T10:47:51.440915Z","iopub.status.idle":"2022-12-15T11:44:07.934968Z","shell.execute_reply.started":"2022-12-15T10:47:51.440881Z","shell.execute_reply":"2022-12-15T11:44:07.932154Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85999c314b8945d6bc7dfbf804819064"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b6aa77ac6743f5929a24d48f3f9821"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eda520b538b4972939e7d4d513abbd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88401216b5649429cdb475303f5e78a"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nDownloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/507M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78ae1e93e2e143f9a71bac7787cfbc24"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"tensor([1, 1, 1,  ..., 0, 0, 0])\ntensor([0, 0, 1,  ..., 0, 0, 1])\n\nEpoch 1/4 \n","output_type":"stream"},{"name":"stderr","text":"359it [12:11,  2.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3071  Acc: 0.8862\n","output_type":"stream"},{"name":"stderr","text":"160it [03:17,  1.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"test Loss: 0.2330  Acc: 0.9216\nEpoch 2/4 \n","output_type":"stream"},{"name":"stderr","text":"359it [11:41,  1.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2337  Acc: 0.9184\n","output_type":"stream"},{"name":"stderr","text":"160it [02:40,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"test Loss: 0.2234  Acc: 0.9246\nEpoch 3/4 \n","output_type":"stream"},{"name":"stderr","text":"359it [10:09,  1.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2005  Acc: 0.9343\n","output_type":"stream"},{"name":"stderr","text":"160it [02:42,  1.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"test Loss: 0.2146  Acc: 0.9342\nEpoch 4/4 \n","output_type":"stream"},{"name":"stderr","text":"359it [10:10,  1.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1586  Acc: 0.9478\n","output_type":"stream"},{"name":"stderr","text":"160it [02:27,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"test Loss: 0.2349  Acc: 0.9285\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_multi(model, df_test):\n    image_test = df_test['image_paths'].to_list()\n    text_test = df_test['Comment'].to_list()\n\n    tmp = np.zeros(len(text_test))\n    net = model\n    net.eval()\n    Data_test, attention_test = net.tokenize(text_test, image_test, tmp, 'test')\n\n    attention = attention_test\n\n    list_tmp = []\n    list_truth = np.array([])\n\n    for (inputs, images, labels), i_attention in tqdm(zip(Data_test, attention), position=0, leave=True):\n        inputs = inputs.to(device)\n        images = images.to(device)\n        labels = labels.to(device)\n        i_attention = i_attention.to(device)\n        \n        with torch.no_grad():\n\n            outputs = net(inputs,images, i_attention)\n\n            list_tmp.append(outputs)\n\n            _, preds = torch.max(outputs, 1)\n\n            del outputs\n            torch.cuda.empty_cache()\n            gc.collect()\n\n            list_truth = np.append(list_truth,preds.cpu().numpy())\n    \n    list_prob = []\n    for i in range(len(list_tmp)):\n        probs = F.softmax(list_tmp[i], dim=1) # assuming logits has the shape [batch_size, nb_classes]\n        list_prob.append(probs)\n    \n    list_ans = []\n    for i in list_prob:\n        list_ans = np.append(list_ans,i.cpu().numpy()[:,1])\n        \n    return list_truth, list_ans","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:44:07.939947Z","iopub.execute_input":"2022-12-15T11:44:07.940810Z","iopub.status.idle":"2022-12-15T11:44:07.952605Z","shell.execute_reply.started":"2022-12-15T11:44:07.940769Z","shell.execute_reply":"2022-12-15T11:44:07.951610Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"mb_new = Multimodal_Bert_Vgg()\nw = torch.load('/kaggle/working/full_multimodal_model_fold1.pth')\nmb_new.load_state_dict(w)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:44:07.953943Z","iopub.execute_input":"2022-12-15T11:44:07.954729Z","iopub.status.idle":"2022-12-15T11:44:25.166983Z","shell.execute_reply.started":"2022-12-15T11:44:07.954692Z","shell.execute_reply":"2022-12-15T11:44:25.166080Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nlist_predict,list_ans = predict_multi(mb_new, df_val)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-15T11:44:25.168448Z","iopub.execute_input":"2022-12-15T11:44:25.168786Z","iopub.status.idle":"2022-12-15T11:47:34.148381Z","shell.execute_reply.started":"2022-12-15T11:44:25.168752Z","shell.execute_reply":"2022-12-15T11:47:34.147294Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"160it [03:05,  1.16s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### submit","metadata":{}},{"cell_type":"code","source":"df_sub = pd.read_csv(TEST_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:47:34.149845Z","iopub.execute_input":"2022-12-15T11:47:34.150778Z","iopub.status.idle":"2022-12-15T11:47:34.257871Z","shell.execute_reply.started":"2022-12-15T11:47:34.150736Z","shell.execute_reply":"2022-12-15T11:47:34.256882Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"list_image_paths = []\n\nfor i in range(df_sub.shape[0]):\n    list_image_paths.append(IMAGE_TEST.format(i))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:47:34.259114Z","iopub.execute_input":"2022-12-15T11:47:34.259478Z","iopub.status.idle":"2022-12-15T11:47:34.267402Z","shell.execute_reply.started":"2022-12-15T11:47:34.259443Z","shell.execute_reply":"2022-12-15T11:47:34.266244Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df_sub['image_paths'] = list_image_paths","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:47:34.268851Z","iopub.execute_input":"2022-12-15T11:47:34.269453Z","iopub.status.idle":"2022-12-15T11:47:34.287702Z","shell.execute_reply.started":"2022-12-15T11:47:34.269417Z","shell.execute_reply":"2022-12-15T11:47:34.286734Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nb = Multimodal_Bert_Vgg()\nw = torch.load('/kaggle/working/full_multimodal_model_fold1.pth')\nb.load_state_dict(w)\nlist_predict, list_ans1 = predict_multi(b, df_sub)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-15T11:47:34.290082Z","iopub.execute_input":"2022-12-15T11:47:34.290404Z","iopub.status.idle":"2022-12-15T11:50:56.879931Z","shell.execute_reply.started":"2022-12-15T11:47:34.290369Z","shell.execute_reply":"2022-12-15T11:50:56.878853Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)\n","output_type":"stream"},{"name":"stderr","text":"160it [03:06,  1.16s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"list_ans1","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:50:56.881532Z","iopub.execute_input":"2022-12-15T11:50:56.883508Z","iopub.status.idle":"2022-12-15T11:50:56.893486Z","shell.execute_reply.started":"2022-12-15T11:50:56.883454Z","shell.execute_reply":"2022-12-15T11:50:56.892289Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"array([0.34242716, 0.36027771, 0.98473722, ..., 0.00424484, 0.94609958,\n       0.97676325])"},"metadata":{}}]},{"cell_type":"code","source":"df_sub['Rating'] = list_ans1","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:53:11.573823Z","iopub.execute_input":"2022-12-15T11:53:11.574188Z","iopub.status.idle":"2022-12-15T11:53:11.579336Z","shell.execute_reply.started":"2022-12-15T11:53:11.574154Z","shell.execute_reply":"2022-12-15T11:53:11.578286Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"df_sub[['RevId','Rating']].to_csv('submission_bert_vgg.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:53:12.227683Z","iopub.execute_input":"2022-12-15T11:53:12.228636Z","iopub.status.idle":"2022-12-15T11:53:12.248207Z","shell.execute_reply.started":"2022-12-15T11:53:12.228595Z","shell.execute_reply":"2022-12-15T11:53:12.247333Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}